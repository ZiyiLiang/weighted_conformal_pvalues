{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e145385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "#from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8fbb7",
   "metadata": {},
   "source": [
    "## Preparing Train, Test, and Validation Data\n",
    "\n",
    "The training data is comprised of ONLY car images from the Natural Images and Stanford Cars Dataset. The validation and test data contain car images from the same datasets as well as other image types (listed below) from the Natural Images dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b161c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare images for resnet50\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in tqdm(img_paths)]\n",
    "    img_array = np.array([img_to_array(img) for img in tqdm(imgs)])\n",
    "    #output = img_array\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "resnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights='imagenet', \n",
    "                        include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions\n",
    "\n",
    "def save_dataset(X, Y, fold):\n",
    "    data = np.concatenate([Y.reshape(len(Y),1),X],1)\n",
    "    idx_sample = np.random.choice(len(Y),len(Y),replace=False)\n",
    "    data = data[idx_sample]\n",
    "    #fmt = ['%s'] + ['%.18e']*X.shape[1]\n",
    "    np.savetxt(\"/media/msesia/Samsung/data/images_animals_{:d}.csv\".format(fold), data, delimiter=\",\", fmt='%s')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8cc2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1922.34it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4307.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 163s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1960.21it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 3788.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 170s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1947.56it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 3780.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 175s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1290.93it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4193.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 186s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1855.09it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 8790.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 181s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2063.49it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 8783.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 172s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1959.73it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 6078.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 162s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2269.43it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 5121.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 158s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 2206.86it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 5505.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 172s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:02<00:00, 1712.93it/s]\n",
      "100%|██████████| 5000/5000 [00:00<00:00, 6355.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 180s 1s/step\n",
      "Explained variance percentage = 0.88\n"
     ]
    }
   ],
   "source": [
    "data_source = \"/media/msesia/Samsung/data/raw_image_ver/raw_image/training\"\n",
    "\n",
    "label_mappings = {0: 'cat', 1: 'lynx', 2: 'wolf', 3: 'coyote', 4: 'cheetah', 5: 'jaguer', \n",
    "                  6: 'chimpanzee', 7: 'orangutan', 8: 'hamster', 9: 'guinea pig'}\n",
    "\n",
    "# Import all images from natural images data set\n",
    "img_paths_full = []\n",
    "img_labels_full = []\n",
    "for f in os.listdir(data_source):\n",
    "    new_lab = label_mappings[int(f[0])]\n",
    "    new_img_path = data_source + \"/\" + f\n",
    "    img_paths_full.append(new_img_path)\n",
    "    img_labels_full.append(new_lab)\n",
    "\n",
    "\n",
    "# Downsample and process\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=True)\n",
    "fold = 0\n",
    "for _, idx in kf.split(np.arange(len(img_labels_full))):\n",
    "    img_paths = np.array(img_paths_full)[idx]\n",
    "    img_labels = np.array(img_labels_full)[idx]\n",
    "    \n",
    "    X_data = read_and_prep_images(img_paths)\n",
    "    \n",
    "    X_data = resnet_model.predict(X_data)\n",
    "    \n",
    "    # Apply standard scaler to output from resnet50\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_data)\n",
    "    X_data = ss.transform(X_data)\n",
    "\n",
    "    # Take PCA to reduce feature space dimensionality\n",
    "    pca = PCA(n_components=512, whiten=True)\n",
    "    pca = pca.fit(X_data)\n",
    "    print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "    X_data = pca.transform(X_data)\n",
    "\n",
    "    Y_data = np.array(img_labels)\n",
    "    save_dataset(X_data, Y_data, fold)\n",
    "\n",
    "    fold = fold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
