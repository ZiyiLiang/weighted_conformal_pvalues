{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3d31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "#from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac0a8a7",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The training data is comprised of ONLY car images from the Natural Images and Stanford Cars Dataset. The validation and test data contain car images from the same datasets as well as other image types (listed below) from the Natural Images dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbee7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"/media/msesia/Samsung/data\"\n",
    "\n",
    "img_paths = []\n",
    "img_labels = []\n",
    "for d in [d for d in os.listdir(data_source + \"/images-flowers/\")]:\n",
    "    img_dir_na = data_source + \"/images-flowers/\"+d\n",
    "    new_img_paths = [join(img_dir_na,filename) for filename in os.listdir(img_dir_na)]\n",
    "    img_paths.append(new_img_paths)\n",
    "    img_labels.append([d]*len(new_img_paths))\n",
    "\n",
    "img_paths_flat = [item for sublist in img_paths for item in sublist]\n",
    "img_labels_flat = [item for sublist in img_labels for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6335404",
   "metadata": {},
   "source": [
    "## Feature Extraction With ResNet50\n",
    "\n",
    "Removing the prediction layer of the pretrained Resnet50 model allows features to quickly be extracted from selected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bc0c71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3670/3670 [00:07<00:00, 488.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare images for resnet50\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in tqdm(img_paths)]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    #output = img_array\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "X_data = read_and_prep_images(img_paths_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9aa8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights='imagenet', \n",
    "                        include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff9910ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 114s 982ms/step\n"
     ]
    }
   ],
   "source": [
    "X_data = resnet_model.predict(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3008da",
   "metadata": {},
   "source": [
    "## Scaling and PCA\n",
    "\n",
    "Reducing the dimensionality of extracted features allow for quicker training times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f53d80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance percentage = 0.88\n"
     ]
    }
   ],
   "source": [
    "# Apply standard scaler to output from resnet50\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_data)\n",
    "X_data = ss.transform(X_data)\n",
    "\n",
    "# Take PCA to reduce feature space dimensionality\n",
    "pca = PCA(n_components=512, whiten=True)\n",
    "pca = pca.fit(X_data)\n",
    "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "X_data = pca.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cfd40",
   "metadata": {},
   "source": [
    "## Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a70a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, Y):\n",
    "    data = np.concatenate([Y.reshape(len(Y),1),X],1)\n",
    "    idx_sample = np.random.choice(len(Y),len(Y),replace=False)\n",
    "    data = data[idx_sample]\n",
    "    #fmt = ['%s'] + ['%.18e']*X.shape[1]\n",
    "    np.savetxt(\"/media/msesia/Samsung/data/images_flowers.csv\", data, delimiter=\",\", fmt='%s')\n",
    "    return data\n",
    "\n",
    "Y_data = np.array(img_labels_flat)\n",
    "data_save = make_dataset(X_data, Y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
