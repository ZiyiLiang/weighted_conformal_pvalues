{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab61c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from IPython.display import Image, display\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "from PIL import ImageFile\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "#from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ca0e0",
   "metadata": {},
   "source": [
    "## Preparing Train, Test, and Validation Data\n",
    "\n",
    "The training data is comprised of ONLY car images from the Natural Images and Stanford Cars Dataset. The validation and test data contain car images from the same datasets as well as other image types (listed below) from the Natural Images dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f80753",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"/media/msesia/Samsung/data/occ_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f983e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all images from natural images data set\n",
    "img_natural_paths = []\n",
    "img_natural_labels = []\n",
    "for d in [d for d in os.listdir(data_source + \"/natural-images/\")]:\n",
    "    img_dir_na = data_source + \"/natural-images/\"+d\n",
    "    new_img_paths = [join(img_dir_na,filename) for filename in os.listdir(img_dir_na)]\n",
    "    img_natural_paths.append(new_img_paths)\n",
    "    img_natural_labels.append([d]*len(new_img_paths))\n",
    "\n",
    "img_natural_paths = [item for sublist in img_natural_paths for item in sublist]\n",
    "img_natural_labels = [item for sublist in img_natural_labels for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a11cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car images from stanford cars\n",
    "train_img_dir_s = data_source + \"/stanford-cars-dataset/cars_train/cars_train\"\n",
    "all_train_img_paths_s = [join(train_img_dir_s,filename) for filename in os.listdir(train_img_dir_s)]\n",
    "\n",
    "train_img_dir_s_test = data_source + \"/stanford-cars-dataset/cars_test/cars_test\"\n",
    "all_train_img_paths_s_test = [join(train_img_dir_s_test,filename) for filename in os.listdir(train_img_dir_s_test)]\n",
    "\n",
    "img_stanford_paths = all_train_img_paths_s + all_train_img_paths_s_test\n",
    "img_stanford_labels = ['car'] * len(img_stanford_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aec76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine lists of images\n",
    "img_paths = img_natural_paths + img_stanford_paths\n",
    "img_labels = img_natural_labels + img_stanford_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f6a5c",
   "metadata": {},
   "source": [
    "## Feature Extraction With ResNet50\n",
    "\n",
    "Removing the prediction layer of the pretrained Resnet50 model allows features to quickly be extracted from selected images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1110f759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23084/23084 [01:53<00:00, 203.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare images for resnet50\n",
    "image_size = 224\n",
    "\n",
    "def read_and_prep_images(img_paths, img_height=image_size, img_width=image_size):\n",
    "    imgs = [load_img(img_path, target_size=(img_height, img_width)) for img_path in tqdm(img_paths)]\n",
    "    img_array = np.array([img_to_array(img) for img in imgs])\n",
    "    #output = img_array\n",
    "    output = preprocess_input(img_array)\n",
    "    return(output)\n",
    "\n",
    "X_data = read_and_prep_images(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0acf2194",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet50(input_shape=(image_size, image_size, 3), weights='imagenet', \n",
    "                        include_top=False, pooling='avg')  # Since top layer is the fc layer used for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3eadab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722/722 [==============================] - 844s 1s/step\n"
     ]
    }
   ],
   "source": [
    "X_data = resnet_model.predict(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bad7da",
   "metadata": {},
   "source": [
    "## Scaling and PCA\n",
    "\n",
    "Reducing the dimensionality of extracted features allow for quicker training times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4465b7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance percentage = 0.86\n"
     ]
    }
   ],
   "source": [
    "# Apply standard scaler to output from resnet50\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_data)\n",
    "X_data = ss.transform(X_data)\n",
    "\n",
    "# Take PCA to reduce feature space dimensionality\n",
    "pca = PCA(n_components=512, whiten=True)\n",
    "pca = pca.fit(X_data)\n",
    "print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))\n",
    "X_data = pca.transform(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f55404",
   "metadata": {},
   "source": [
    "## Save the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c76f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, Y):\n",
    "    data = np.concatenate([Y.reshape(len(Y),1),X],1)\n",
    "    idx_sample = np.random.choice(len(Y),len(Y),replace=False)\n",
    "    data = data[idx_sample]\n",
    "    #fmt = ['%s'] + ['%.18e']*X.shape[1]\n",
    "    np.savetxt(\"/media/msesia/Samsung/data/images_cars.csv\", data, delimiter=\",\", fmt='%s')\n",
    "    return data\n",
    "\n",
    "Y_data = np.array(img_labels)\n",
    "data_save = make_dataset(X_data, Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a2cea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
